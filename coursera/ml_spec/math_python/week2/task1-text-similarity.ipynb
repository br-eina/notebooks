{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T11:08:22.557688Z",
     "start_time": "2020-09-03T11:08:22.555024Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T11:08:23.030891Z",
     "start_time": "2020-09-03T11:08:23.019041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(18, 0.956644501523794),\n",
       " (2, 0.9527544408738466),\n",
       " (16, 0.9442721787424647),\n",
       " (19, 0.9442721787424647),\n",
       " (6, 0.9402385695332803),\n",
       " (8, 0.9258750683338899),\n",
       " (10, 0.9055088817476932),\n",
       " (4, 0.8951715163278082),\n",
       " (20, 0.8885443574849294),\n",
       " (9, 0.8842724875284311),\n",
       " (12, 0.8804771390665607),\n",
       " (15, 0.8740118423302576),\n",
       " (14, 0.8703592552895671),\n",
       " (3, 0.8644738145642124),\n",
       " (21, 0.8427572744917122),\n",
       " (17, 0.8406361854220809),\n",
       " (13, 0.8396432548525454),\n",
       " (11, 0.8328165362273942),\n",
       " (22, 0.8250364469440588),\n",
       " (5, 0.7770887149698589),\n",
       " (7, 0.7327387580875756),\n",
       " (1, 0.0)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('sentences.txt', 'r')\n",
    "lines = []\n",
    "\n",
    "with open('sentences.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.rstrip().lower()\n",
    "        lines.append(line)\n",
    "\n",
    "words_ind = {}\n",
    "tokenized_lines = []\n",
    "i = 0\n",
    "\n",
    "for line in lines:\n",
    "    tokenized_line = []\n",
    "    for token in re.split('[^a-z]', line):\n",
    "        if token:\n",
    "            tokenized_line.append(token)\n",
    "            if token not in words_ind:\n",
    "                words_ind[token] = i\n",
    "                i += 1\n",
    "    tokenized_lines.append(tokenized_line)\n",
    "\n",
    "freq_matrix = np.zeros((len(lines), len(words_ind)))\n",
    "\n",
    "for ind_row, line in enumerate(tokenized_lines):\n",
    "    for word in line:\n",
    "        freq_matrix[ind_row, words_ind[word]] += 1\n",
    "\n",
    "distances = {}\n",
    "for ind_row in range(len(lines)):\n",
    "    distances[ind_row+1] = cosine(freq_matrix[0, :], freq_matrix[ind_row, :])\n",
    "    \n",
    "sorted(distances.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_spec] *",
   "language": "python",
   "name": "conda-env-ml_spec-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
